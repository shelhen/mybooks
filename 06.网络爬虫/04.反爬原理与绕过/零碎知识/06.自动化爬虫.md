## 06.自动化工具

目前，很多网站都采用 Ajax 等技术进行动态加载数据，想要采集这类网站的数据，需要通过抓包对网站的数据接口进行分析，去寻找想要采集的数据由哪个接口传输。而且，就算找到了数据接口，这些接口可能也是被加密过的，想要通过接口获取数据，需要对加密参数进行逆向分析，这个过程对于初学者来说非常复杂。

为了解决这些问题，能够更加简单的进行爬取数据，我们可以使用到一些自动化工具，如 Selenium、playwright、pyppeteer 等，所谓的自动化是指，我们可以通过代码的形式制定一系列的行为动作，然后执行代码，这些动作就会同步触发在浏览器中。这些工具可以模拟浏览器运行，直接获取到数据加载完成后的网页源码，这样我们就可以省去复杂的抓包、逆向流程，直接拿到数据。

### 一、Selenium 的使用

Selenium是一个Web的自动化测试工具，最初是为网站自动化测试而开发的，Selenium 可以直接调用浏览器，它支持所有主流的浏览器（包括PhantomJS这些无界面的浏览器），可以接收指令，让浏览器自动加载页面，获取需要的数据，甚至页面截屏等，[Selenium 非官方参考文档](http://selenium-python.readthedocs.io/index.html)/[Selenium非官方中文文档](https://selenium-python-zh.readthedocs.io/en/latest/faq.html)/[官方文档](https://www.selenium.dev/documentation/overview/)。

```
pip install selenium
```

Selenium 自己不带浏览器，不支持浏览器的功能，它需要与第三方浏览器结合在一起才能使用。但是我们有时候需要让它内嵌在代码中运行，所以可以用一个叫 无头浏览器 的工具代替真实的浏览器。

无头浏览器是指“无界面”(headless)的浏览器，它会把网站加载到内存并执行页面上的 JavaScript，因为不会展示图形界面，所以运行起来比完整的浏览器要高效，又因为其内置了完整的浏览器功能，故其运行相较与`requests`更低效。

如果把 Selenium 和 无头浏览器 结合在一起，就可以运行一个非常强大的网络爬虫了，这个爬虫可以处理 JavaScrip、Cookie、headers，以及任何真实用户需要做的事情。

#### 1.无头浏览器的使用场景与工作原理

##### 1）使用场景

```
# 无头浏览器，适合部署到服务器时使用，但是容易被反爬
driver = webdriver.PhantomJS()

# 有头浏览器，适合用在开发过程中
driver = webdriver.Chrome()
```

> 绝大多数服务器是没有界面的，selenium控制谷歌浏览器也可以做到无界面开启。macOS中Chrome59+版本，Linux中57+版本，Windows中6+版本才支持。

##### 2）工作原理

利用浏览器原生的API，封装成一套更加面向对象的Selenium WebDriver API，直接操作浏览器页面里的元素，甚至操作浏览器本身（截屏，窗口大小，启动，关闭，安装插件，配置证书之类的）。

![image-20230720195230348](./imgs/image-20230720195230348.png)

##### 3）其他各驱动器下载地址

| [ChromeDriver](https://sites.google.com/a/chromium.org/chromedriver/downloads) |
| :----------------------------------------------------------: |
| [ChromeDriver](https://googlechromelabs.github.io/chrome-for-testing/#stable) |
| [FirefoxDriver](https://github.com/mozilla/geckodriver/releases<br/>：) |
| [EdgeDriver](https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/) |
| [SafariDriver](https://webkit.org/blog/6900/webdriver-support-in-safari-10/) |
|                         [PhantomJS](                         |

安装：下载完成后解压到指定的英文目录即可，这里以Chromedriver的安装为例，首先应该查看当前系统内谷歌浏览器的版本：

![image-20230720195445229](./imgs/image-20230720195445229.png)

访问，点击进入不同版本的chromedriver下载页面，点击notes.txt进入版本说明页面，查看chrome和chromedriver匹配的版本，选择匹配的版本下载，根据操作系统下载正确版本的chromedriver，解压压缩包后获取python代码可以调用的谷歌浏览器的webdriver可执行文件，将该文件放置在项目目录或其他已知路径的目录中。

- windows为`chromedriver.exe`
- linux和macos为`chromedriver`

可以为chromedriver添加环境变量

- windows环境下需要将 chromedriver.exe 所在的目录设置为path环境变量中的路径
- linux/mac环境下，将 chromedriver 所在的目录设置到系统的PATH环境值中

```python
# 若已设置环境变量，调用时
driver = webdriver.Chrome()
# 若无法通过上述代码调用，可以尝试将chromedriver 所在的目录设置到系统的PATH环境
# 或者按照环境路径来打开
from selenium.webdriver.chrome.service import Service
service = Service(executable_path='./datas/chromedriver.exe', port=1234)
# 注意chromedriver版本必须与当前使用的chrome版本一致
# 版本不一致会报错：Current browser version is 114.0.5735.201 with binary path C:\Program Files\Google\Chrome\Application\chrome.exe
```

#### 2.简单使用

Selenium 提供了一系列实用的 Api，通过它们可以实现更多操作，**注意，最新测试发现，截至到Selenium4.4许多接口发生了变化，具体以使用为准。**

##### 1）浏览器创建与关闭

```python
from selenium import webdriver

browser = webdriver.Chrome()
browser = webdriver.Firefox()
browser = webdriver.Edge()
browser = webdriver.PhantomJS()
browser = webdriver.Safari()

# 向浏览器发送请求
driver.get('https://www.baidu.com')
# 退出浏览器
driver.quit()
```

##### 2）元素定位

```python
from selenium import webdriver

# <div class="cheese"; id ="su"; name="email">cheese<div>
# <a href="http://www.google.com/search?q=cheese">cheese</a>
# <a href="http://www.google.com/search?q=cheese">search for cheese</a>>
driver = webdriver.Chrome()

# 根据id定位元素
submitTag11 = driver.find_element_by_id('su')
# 根据类选择器定位元素
submitTag21 = driver.find_element_by_class_name('cheese') 
submitTag22 = driver.find_elements_by_class_name('cheese')
# 根据标签的name属性值返回包含标签对象元素的列表
submitTag31 = driver.find_element_by_name('email')
submitTag32 = driver.find_elements_by_name('email')
# 根据标签名获取元素列表
submitTag41 = driver.find_element_by_tag_name('div')
submitTag42 = driver.find_elements_by_tag_name('div')
# 根据xpath语法定位元素
submitTag51 = driver.find_element_by_xpath('div')
submitTag52 = driver.find_elements_by_xpath('div')
# 根据CSS选择器定位元素
submitTag61 = driver.find_element_by_css_selector('//div')
submitTag62 = driver.find_elements_by_css_selector('//div')
# 根据连接文本获取元素列表
submitTag71 = driver.find_element_by_link_text("cheese")
submitTag72 = driver.find_elements_by_link_text("cheese")
# 根据链接包含的文本获取元素列表
submitTag81 = driver.find_element_by_partial_link_text("cheese")
submitTag82 = driver.find_elements_by_partial_link_text("cheese")
# 区别 全部文本和包含某个文本

from selenium.webdriver.common.by import By

submitTag12 = driver.find_element(By.ID,'su')
submitTag23 = driver.find_element(By.CLASS_NAME,'cheese')
submitTag33 = driver.find_element(By.NAME,'email')
submitTag43 = driver.find_element(By.TAG_NAME,'div')
submitTag53 = driver.find_element(By.XPATH,'div')
submitTag63 = driver.find_element(By.CSS_SELECTOR,'//div')
submitTag73 = driver.find_element(By.LINK_TEXT, "cheese")
submitTag83 = driver.find_element(By.PARTIAL_LINK_TEXT, "cheese")
```

> `find_element`和`find_elements`的区别，多了个`s`就返回列表，没有`s`就返回匹配到的第一个标签对象，`find_element`匹配不到就抛出异常，`find_elements`匹配不到就返回空列表。

##### 3）页面操作

在使用selenium过程中，实例化driver对象后，driver对象有一些常用的属性和方法，下面是一些易于理解的常用操作：

| 属性或方法                     | 说明                                                         |
| ------------------------------ | ------------------------------------------------------------ |
| `driver.page_source`           | 当前标签页浏览器渲染之后的网页源代码                         |
| `driver.current_url`           | 当前标签页的url                                              |
| `driver.close()`               | 关闭当前标签页，如果只有一个标签页则关闭整个浏览器           |
| `driver.quit()`                | 关闭浏览器                                                   |
| `driver.forward()`             | 页面前进                                                     |
| `driver.back()`                | 页面后退                                                     |
| `driver.screen_shot(img_name)` | 页面截图                                                     |
| `driver.get_cookies(key)`      | 根据cookie的name获取cookie的值，默认获取所有cookie。         |
| `driver.delete_cookie(key)`    | 根据cookie的name删除cookie的值，`delete_all_cookies()`删除所有cookie。 |

除此之外，`chrome`还提供了一系列接口来处理页面时间和用户操作，如模拟一些鼠键操作：双击、右击、拖拽甚至按住不动等，可以通过导入 ActionChains 类来实现，

| 属性或方法                              | 说明                     |
| --------------------------------------- | ------------------------ |
| `actions.move_to_element(element)`      | 鼠标移动到 element 位置  |
| `actions.click(element)`                | 单击                     |
| `actions.double_click(element)`         | 双击                     |
| `actions.context_click(element) `       | 右击                     |
| `actions.click_and_hold(element)`       | 点击但不松开鼠标         |
| `action.drag_and_drop(element, target)` | 拖放元素                 |
| `action.switch_to_window("windowName")` | 在不同的`frames`之间移动 |
| `action.scroll_to_element(iframe)`      | 按照`frames`鼠标滚轮移动 |
| `action.scroll_by_amount(0, delta_y)`   | 鼠标按给定值滚动         |

下面是一些案例

```python
from selenium import webdriver
# 或直接导入 ActionChains 类  
from selenium.webdriver import ActionChains

driver = webdriver.Chrome()

# 动作一个一个地排队，然后执行
actions = webdriver.ActionChains(driver) 

actions.move_to_element(element) # 
actions.click(element)  # 
actions.double_click(element)  # 
actions.context_click(element)   # 
actions.click_and_hold(element)  # 

# switch_to_window("windowName")  # 在不同的标签页面之间移动
# action.drag_and_drop(element, target).perform()  # 拖放元素

ActionChains(driver).scroll_to_element(iframe).perform()
# 按给定值滚动，(0, delta_y) 为向右和向下滚动的量，负值则反之。
footer = driver.find_element(By.TAG_NAME, "footer")
delta_y = footer.rect['y']
ActionChains(driver).scroll_by_amount(0, delta_y).perform()

actions.perform() # 执行

# 执行链式操作
webdriver.ActionChains(driver).move_to_element(element).click(element).double_click(element).context_click(element).click_and_hold(element).perform()
# 无论哪种方式，操作都按照它们被调用的顺序执行，一个接一个。
```

`chrome`也可以直接操作表单元素，

| 属性或方法                             | 说明                  |
| -------------------------------------- | --------------------- |
| `element.send_keys(wordstring)`        | `input`元素中输入内容 |
| `element.clear()`                      | 清空输入框的数据      |
| `select`标签具体操作有所不同，如下案例 |                       |
| `element.submit()`                     | 提交表单              |

##### 4）表单操作

```python
from selenium import webdriver

driver = webdriver.Chrome()
# 使用send_keys(value)向输入框填充数据
inputTag = driver.find_element_by_id('kw')


inputTag.send_keys('python')
# 使用clear()清空输入框的数据
inputTag.clear()

# 要选中checkbox标签，需要先选中这个标签，然后执行click事件。
rememberTag = driver.find_element_by_name("rememberMe")
rememberTag.click()

# select元素不能直接点击。因为点击后还需要选中元素，需要导入Select类
from selenium.webdriver.support.ui import Select
# 找到 name 的选项卡
select = Select(driver.find_element_by_name('status'))
# 通过索引选取
select.select_by_index(1)
# value是option标签的一个属性值，并不是显示在下拉框中的值
select.select_by_value("0")
# visible_text是在option标签文本的值，是显示在下拉框的值
select.select_by_visible_text(u"未审核")
# 全部取消选择
select.deselect_all()

# 提交表单
element.submit()
driver.find_element_by_id("submit").click()
```

##### 5）页面操作

一个浏览器肯定会有很多窗口，所以我们肯定要有方法来实现窗口的切换，为了避免一些`ajax`请求导致页面尚未刷新就开始获取数据，我们需要执行一些浏览器等待，常见的等待分为隐式等待和显式等待。**隐式等待是等待特定的时间，显式等待是指定某一条件直到这个条件成立时继续执行。**

```python
from selenium import webdriver
# WebDriverWait 库，负责循环等待
from selenium.webdriver.support.ui import WebDriverWait
# expected_conditions 类，负责条件出发
from selenium.webdriver.support import expected_conditions as EC


driver = webdriver.Chrome()

# 隐式等待比较简单，就是简单地设置一个等待时间，单位为秒,如果不设置，默认等待时间为0
driver.implicitly_wait(10) # seconds

driver.switch_to.window("name")
# 使用 window_handles 方法来获取每个窗口的操作对象
for handle in driver.window_handles:
    driver.switch_to_window(handle)
    

# 当触发了某个事件之后，页面出现了弹窗提示，使用如下方法处理这个提示或者获取提示信息
alert = driver.switch_to_alert()

driver.get("http://www.xxxxx.com/loading")
try:
    # 显示等待：页面一直循环，直到 id="myDynamicElement" 出现
    element = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.ID, "myDynamicElement"))
    )
finally:
    driver.quit()
```

> 在上面的代码中，Selenium 将等待最多 10 秒以找到匹配给定条件的元素。如果在那段时间内没有找到任何元素，则抛出 TimeoutException。默认情况下，WebDriverWait 每 500 毫秒调用一次 ExpectedCondition，直到它返回成功。ExpectedCondition 将在成功的情况下返回true（布尔值）， 如果未能找到元素，则返回null 。

下面是一些内置的等待条件，你可以直接调用这些条件，而不用自己写某些等待条件了。

```python
title_is
title_contains
presence_of_element_located
visibility_of_element_located
visibility_of
presence_of_all_elements_located
text_to_be_present_in_element
text_to_be_present_in_element_value
frame_to_be_available_and_switch_to_it
invisibility_of_element_located
element_to_be_clickable – it is Displayed and Enabled.
staleness_of
element_to_be_selected
element_located_to_be_selected
element_selection_state_to_be
element_located_selection_state_to_be
alert_is_present
```

##### 5）其他配置

无头模式下网站运行不会弹出窗口，可以减少一些资源消耗，也避免了浏览器窗口运行时对设备正常使用带来的影响，在服务器上运行需要用到。但是无头模式下被网站检测的特征点非常多，因此需要根据自己的应用场景来使用。

```python
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import time

# 创建一个参数对象，用来控制chrome以无界面模式打开
chrome_options = Options()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--disable-gpu')
# 驱动路径
path = './chromedriver'
# 创建浏览器对象
browser = webdriver.Chrome(executable_path=path,options=chrome_options)

# 上网
url = 'http://www.baidu.com/'
browser.get(url)

browser.save_screenshot('baidu.png')

browser.quit()
```

对于某些操作，Selenium API并没有提供。比如，下拉进度条，可以直接模拟运行JavaScript，此时使用`execute_script()`方法即可实现。

```python
from selenium import webdriver
from time import sleep
#1.创建一个浏览器对象,executable_path指定当前浏览器的驱动程序
#注意：我当前是mac系统，驱动程序也是mac版本的，如果是window系统注意更换驱动
bro = webdriver.Chrome(executable_path='./chromedriver')
#2.浏览器的请求发送
bro.get('https://www.jd.com/')
#3.标签定位:调用find系列的函数进行标签定位
search_box = bro.find_element_by_xpath('//*[@id="key"]')
#4.节点交互
search_box.send_keys('mac pro m1')#向指定标签中录入内容
sleep(2)
btn = bro.find_element_by_xpath('//*[@id="search"]/div/div[2]/button')
btn.click() #点击按钮
sleep(2)
#js注入
bro.execute_script('document.documentElement.scrollTo(0,2000)')
sleep(5)
#关闭浏览器
bro.quit()
```

Options常用参数

```python
options.add_argument('--headless')                     # 开启无界面模式
options.add_argument("--disable-gpu")                  # 禁用gpu
options.add_argument('--user-agent=Mozilla/5.0 HAHA')  # 配置对象添加替换User-Agent的命令
options.add_argument('--window-size=1366,768')         # 设置浏览器分辨率（窗口大小）
options.add_argument('--start-maximized')              # 最大化运行（全屏窗口）,不设置，取元素会报错
options.add_argument('--disable-infobars')             # 禁用浏览器正在被自动化程序控制的提示
options.add_argument('--incognito')                    # 隐身模式（无痕模式）
options.add_argument('--disable-javascript')           # 禁用javascript
options.add_argument(f"--proxy-server=http://ip:port")  # 使用代理
options.add_argument('blink-settings=imagesEnabled=false')  # 不加载图片, 提升速度

# 其它
--user-data-dir=”[PATH]” 指定用户文件夹User Data路径，可以把书签这样的用户数据保存在系统分区以外的分区。
--disk-cache-dir=”[PATH]“ 指定缓存Cache路径
--disk-cache-size= 指定Cache大小，单位Byte
--first run 重置到初始状态，第一次运行
--incognito 隐身模式启动
--disable-javascript 禁用Javascript
--omnibox-popup-count="num" 将地址栏弹出的提示菜单数量改为num个。我都改为15个了。
--user-agent="xxxxxxxx" 修改HTTP请求头部的Agent字符串，可以通过about:version页面查看修改效果
--proxy-server	使用给定的代理服务器，这个参数只对 http 和 https 有效。
--disable-plugins 禁止加载所有插件，可以增加速度。可以通过about:plugins页面查看效果
--disable-javascript 禁用JavaScript，如果觉得速度慢在加上这个
--disable-java 禁用java
--start-maximized 启动就最大化
--no-sandbox 取消沙盒模式
--single-process 单进程运行
--process-per-tab 每个标签使用单独进程
--process-per-site 每个站点使用单独进程
--in-process-plugins 插件不启用单独进程
--disable-popup-blocking 禁用弹出拦截
--disable-plugins 禁用插件
--disable-images 禁用图像
--incognito 启动进入隐身模式
--allow-outdated-plugins	不停用过期的插件。
--disable-accelerated-2d-canvas	停用 GPU 加速二维画布。
--disable-accelerated-video	停用 GPU 加速视频。
--disable-dart	停用 Dart。
--disable-desktop-notifications	禁用桌面通知，在 Windows 中桌面通知默认是启用的。
--disable-extensions	禁用拓展。
--disable-file-system	停用 FileSystem API
--disable-java	停用 Java。
--disable-local-storage	禁用 LocalStorage。
```

#### 3.规避检测

`selenium`自动化工具存在很明显的缺陷，就是容易被网站检测到，而且现在不少网站有对selenium采取了监测机制，比如正常情况下我们用浏览器访问淘宝等网站的 `window.navigator.webdriver`的值为` undefined`或者为`false`。而使用`selenium`访问则该值为`true`，网站可以通过检测这些特征来禁止 Selenium 访问。

通过js注入，绕过检测。

```python
from selenium.webdriver import ActionChains
from selenium.webdriver import Chrome
from selenium.webdriver.chrome.options import Options

chrome_options = Options()
chrome_options.add_argument("--disable-blink-features=AutomationControlled")
chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36')

options.add_argument("--disable-blink-features=AutomationControlled")
# navigator.webdriver 设置为 false
options.add_argument("--disable-blink-features=AutomationControlled")
# 隐藏"Chrome正在受到自动软件的控制"提示
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option('useAutomationExtension', False)
# 禁用拓展。
options.add_argument("--disable-extensions")
# --disable-plugins 禁止加载所有插件，可以增加速度。可以通过about:plugins页面查看效果
# --disable-javascript 禁用JavaScript，如果觉得速度慢在加上这个
driver = Chrome('./chromedriver',options=chrome_options)
#Selenium在打开任何页面之前，先运行这个Js文件。
with open('./stealth.min.js') as f:
    js = f.read()
#进行js注入，绕过检测
#execute_cdp_cmd执行cdp命令（在浏览器开发者工具中执行相关指令，完成相关操作）
#Page.addScriptToEvaluateOnNewDocument执行脚本
driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
  "source": js
})

# 将浏览器navigator.webdriver重置为False
chrome.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
  "source": """
    Object.defineProperty(navigator, 'webdriver', {
      get: () => false
    })
  """
})

driver.get('https://www.taobao.com')
```

stealth.min.js 来自于 puppeteer 的一个插件，puppeteer 是一个控制 headless Chrome 的 Node.js API ，puppeteer 有一个插件名为 puppeteer-extra-plugin-stealth，它的开发目的就是为了防止 puppeteer 被检测，它可以隐藏许多自动化特征。puppeteer-extra 的作者也编写了一个脚本，用于将最新的特征隐藏方法puppeteer-extra-stealth 提取到 JS 文件之中，生成的 JS 文件可以用于纯 CDP 实现，也可以用于测试开发工具中的检测规避。而 Selenium 正好支持 CDP 的调用，CDP 全称（Chrome DevTools Protocol），利用它可以在浏览器加载之前执行 JS 语句。

如果你已经安装了 node.js ，`npx extract-stealth-evasions` 执行此命令就可以生成 stealth.min.js 文件。

```python
chrome.exe --remote-debugging-port=9222 --user-data-dir=“D:\chrometemp”
# 使用selenium控制该端口浏览器
options=webdriver.ChromeOptions()
options.debugger_address='127.0.0.1:9222'
driver=webdriver.Chrome(options=options)
```

### 二、Playwright 的使用

Playwright是一个用于自动化Web浏览器测试和Web数据抓取的开源库。它由Microsoft开发，支持Chrome、Firefox、Safari、Edge和WebKit浏览器。Playwright的一个主要特点是它能够在所有主要的操作系统（包括Windows、Linux和macOS）上运行，并且它提供了一些强大的功能，如跨浏览器测试、支持无头浏览器、并行执行测试、元素截图和模拟输入等。与 Selenium 相比，Playwright 最大的优点就是不需要手动安装驱动，而且它拥有更好的性能与更多的功能。因此在爬虫领域，Playwright 是更好的选择。

它主要有以下优势：

```
兼容多个浏览器，而且所有浏览器都使用相同的API。
速度快、稳定性高，即使在大型、复杂的Web应用程序中也可以运行。
支持无头浏览器，因此可以在没有可见界面的情况下运行测试，从而提高测试效率。
提供了丰富的 API，以便于执行各种操作，如截图、模拟输入、拦截网络请求等。
```

使用 Playwright 需要 Python版本在3.7以上，安装完成后需要进行初始化操作，安装所需的浏览器。

```
pip install playwright
playwright install
```

执行上述指令时，Playwright 会自动安装多个浏览器（Chromium、Firefox 和 WebKit）并配置驱动，所以该过程速度较慢。











6）防检测

### 三、Pyppeteer 的使用

`stealth.min.js` 文件来源于Puppeteer，Puppeteer是一个基于 Node.js 的自动化工具，Pyppeteer 是基于`Puppeteer`使用 Python 语言封装的 Google Chrome 浏览器的非官方 API，它可以用来进行自动化测试、网站爬虫和数据抓取等工作。它类似于轻量级的 Playwright ，它使用起来更加简单，且 Pyppeteer 与 Playwright 一样都支持异步，性能方面也比较强。缺点就是它能且仅能基于 Chromium 内核，资源消耗比较大，不支持其它浏览器，而且 Pyppeteer 的作者近年来都没对该库进行维护，导致存在一些 bug。

Pyppeteer 的底层是通过调用 Chrome 浏览器的 DevTools Protocol 接口来实现的。DevTools Protocol 是一个基于 WebSocket 协议的远程调试接口，可以让开发者控制和检查 Chrome 浏览器的行为。Pyppeteer 利用这个接口实现了对 Chrome 浏览器的完全控制，包括加载页面、模拟用户操作、获取页面内容等等。

Pyppeteer 支持 Python 3.6 及以上版本，并且可以在 Windows、macOS 和 Linux 等操作系统上运行。它提供了简单易用的 API，可以方便地模拟用户在浏览器上的操作，例如点击链接、填写表单、触发事件等等。同时，它也支持对浏览器的调试、截屏、PDF 导出等高级功能。



Pyppeteer 的安装与 Playwright 相似，首先使用 pip 安装 Pyppeteer 包，安装完成后可以选择执行 `pyppeteer install`下载用于 pyppeteer 的 chromium，这一步可以省略，因为第一次运行 Pyppeteer 时会自动检测是否安装了 chromium 浏览器，如果没有安装程序会自动进行安装配置。

```
pip install pyppeteer
```

因为已经学习了 Selenium 与 Playwright 库的使用方法，自动化库的使用大同小异，这里只介绍 Pyppeteer 中的特殊方法，Pyppeteer 基于异步实现，所以它支持异步操作。



