# 04.变量与数据类型进阶

## 一、赋值与引用

在`Python`中`变量`和`数据`是分开存储的，数据保存在内存中的一个位置，变量中保存着数据在内存中的地址，存储在内存中的数据又可称为`对象`，对象是有类型的，每一个对象都具有**两个标准**的**头部信息**，类型标志符（标识对象的类型）和引用计数器（决定对象是不是进行回收）。变量中记录数据的地址叫做引用，建立变量与数据之间引用关系的操作叫做赋值。

实际上叫做变量的这个东西并不存在，python变量更像是**指针**，指向所引用的对象，**而不是数据存储区域**。引用本身就是我们理解的变量。当变量首次被定义时，会为变量开辟内存，当将数据赋值给变量时，会为数据开辟内存形成对象，并建立对象与变量之间的引用关系。如果为一个已经定义的变量赋值时，本质上是修改了对象的引用。

> 所有的变量，必须 **在使用前 赋值**，**使用未赋值的变量会产生错误**。
>
> 使用 `id()` 函数可以查看变量中保存数据所在的 **内存地址**——对象。

```python
a = 1  # 定义一个整数变量 a，并且赋值为 1
a = 2  # 开辟新的数据内存空间，并在数据和变量之间建立引用。
b = a  # 定义新的变量b，并建立b 与 数据2 之间的引用。

print(id(a))  # 140708464157520
print(id(b))  # 140708464157520
```

### 1.`del`关键字

在学习列表、集合、字典时，存在自有的删除方法`remove`、`pop`等还存在`del`关键字删除，二者有什么区别呢？

`del` 关键字本质上是删除的变量与数据之间的引用（变量），数据将由Python解释器的垃圾回收机制删除，且一旦删除，后续代码不在能使用该变量。因为`remove`等方法则不能用于删除变量，因此其是删除数据。

`remove()`等方法除删除外，一般还有其他限制，如`remove()`搜索并删除第一个匹配到的元素，`pop()`方法删除某元素并返回，因此具体的方法相对于`del`关键字执行效率更低。

> 一般更推荐使用自带的方法删除。

### 2.对象的类型

`Python`语言是一门动态语言，这里的动态是指变量在赋值之前并没有确定类型（整数？字符串？），类型是在运行过程中由解释器自动决定的，而不是通过代码声明（`C#`、`C++`、`Java`等语言在创建变量时需要主动声明其类型），没有必要事先声明变量。与静态语言相比，由于动态语言需要解释其判断变量类型，

因此执行效率较慢——Python也提供了`:`运算符声明变量类型，注意这一点可以提升代码效率，但是动态类型书写更简洁。

补充：https://sikasjc.github.io/2018/07/14/type-hint-in-python/

`Type Hints`仅仅辅助代码检查，不会加快解释器运行速度。

> 变量名本身是没有类型的，**类型**只存在**对象**中，**变量**只是**引用**了**对象**。

**`Python`对象三要素：Id，Type，Value。**

|  标识   |       说明       |
| :-----: | :--------------: |
|  `Id`   | 唯一标识一个对象 |
| `Type`  |  标识对象的类型  |
| `Value` |     对象的值     |

### 3.`== `和 `is`

| 符号 | 判断对象 | 说明                                           |
| ---- | -------- | ---------------------------------------------- |
| `==` | `Value`  | 判断对象的**值**是否相等                       |
| `is` | `id`     | 判断对象的**地址是否相等**，即指**引用相等**。 |

### 4.列表循环删除

```python
li = [11, 22, 33, 44]
for e in li:
    li.remove(e)
print(li)  # [22,44]
```

原因：`for `循环运行过程中，会有一个指针来记录当前循环的元素是哪一个，一开始该指针指向0，紧接着删除第0个元素，这时候，原本是索引为1的元素变为第0个，这时指针指向1，然后删除第一个（对应原列表中索引为2的元素），删除后，原索引为3的元素更新索引为1，此时指针应该指向2，但元素已经迭代完毕，结束循环。

```python
li = [11, 22, 33, 44]
for i in range(len(li)):
    del li[i]  # 报错
```

原因：同上，这里的`i`会依次指向`0,1,2，3`当删除`li[0]、li[1]`后，`li[2]`已经不存在了，`li`中仅包含`li[0]、li[1]`，此时再去删除`li[2]`将引发异常。

> 直接使用`for` 循环遍历列表，当指针指向的索引大于列表本身长度时会停止迭代，`for-i`循环会强制循环完整个列表的长度，注意二者的不同。

```python
li = [11, 22, 33, 44]
for e in li:
    li.pop()
print(li)  # [11, 22]
```

原因：同第一次，`pop()`函数删除最后一个元素，而直接使用`for`循环遍历只能迭代两次，只能删除`33`和`44`。

```python
li = [11, 22, 33, 44]
for e in range(len(li)):
    li.pop()
print(li)  # []
```

强制迭代四次，每次删除最后一个元素。

## 二、深拷贝与浅拷贝

浅拷贝是指为创建一个新的变量并建立新变量与原数据之间的引用；深拷贝是指创建一个新的变量，并开辟新的内存，将原数据进行递归拷贝到新内存中，并建立新数据与新变量之间的引用，此时新变量与原变量之间没有任何关系。通俗点理解，浅拷贝类似于创建数据的快捷方式，深拷贝才是我们理解的数据拷贝。

### 1.可变类型与不可变类型

在上一章中，我们了解了什么是可变类型与不可变类型，但是不太明白可变类型与不可变类型的主要区别，这里进一步学习。首先可变类型是指数据能够直接进行修改的数据类型，不可变类型是指数据不能够直接修改的数据类型，==可变类型又可称之为动态类型。==

由于计算机中内存是固定的，因此更适合存储不可变类型，但为了满足数据变化的需要，还是建立的可变类型，对于可变类型而言，从内存的角度理解，当为数据开辟内存时会开辟一定的空间用来保存数据，当数据内容发生变化时，会重新分配内存，并且为了减少重新分配内存的次数，通常每次重新分配时，大小都为原来的k倍。k值越大，则重新分配内存的次数越少，但浪费的空间越多。==动态数据类型与静态数据类型相比，浪费了更多内存、占用了更多资源。==

| 可变类型（动态类型） |  不可变类型（静态类型）  |
| :------------------: | :----------------------: |
|   列表、字典、集合   | 布尔、数值、字符串、元组 |

**哈希 `(hash)`**：是一种 **算法**，其作用就是提取数据的 **特征码（指纹）**，**相同的内容** 得到 **相同的结果**，**不同的内容** 得到 **不同的结果**。`Python` 中内置了一个 `hash(o)` 函数，该函数将接收一个 **不可变类型** 数据作为 **参数**，返回一个整数结果。

在 `Python` 中，设置字典的 **键值对** 时，会首先对 `key` 进行 `hash` 已决定如何在内存中保存字典的数据，以方便 **后续** 对字典的操作：**增、删、改、查**，因此字典的`key`必须是不可变类型。

> **可变类型**的数据变化通过 **方法** 来实现；

### 2.小数据池与缓存驻留机制

```python
a = 1
b = [1,2]
c = a
d = b
e = 1
f = [1,2]
print(id(a), id(c), id(e))  # 140733791724328 140733791724328 140733791724328
print(id(b), id(d), id(f))  # 2159223589696 2159223589696 2159223593920
```

小数据池是一种数据缓存机制，其他语言也称之为“驻留机制”或“常量池”，它实质是指对于`整数`、`字符串`、`布尔值`这类非容器类型，**其对象内存中的地址是固定池化的，只要其对象的数值相等，其引用的一定是同一个对象。**

> 整数驻留机制池中仅仅包括`-5~256`内的整数；对于字符串而言，若字符串的长度小于1，都会进行池化，当长度大于1小于20时，当且仅当字符串中仅包含字母，数字，下划线时才会缓存。
>
> 可以使用`sys`模块中的`intern()`新增驻留内容提高代码效率。

由于不可变类型数据其内存总是不变的，因此在同一段代码块中，python解释器会将其内所有的不可变类型加入缓存池，当再次初始化新对象时，会检查是否其值是否已经存在，如果存在，会将其重用。

### 3.赋值运算

赋值就是创建了对象的一个新的引用，赋值并不会产生一个独立的对象，它只是给原有的数据对象添加一个新的标签。所以当其中的一个标签被改变的时候，数据对象就会发生变化，另一个标签也会随之改变。**Python中的赋值都是进行对象的引用传递**，即内存地址的传递。

#### （1）可变类型的赋值运算

```python
lst1 = [1, 2, 3]
lst2 = lst1
lst3 = [1, 2, 3]

print(lst1,id(lst1)) #查看列表、引用地址 Id()函数
print(lst2,id(lst2))
print(lst3,id(lst3))
```

由上可知，lst1 和 lst2 指向同一个对象，lst1 和 lst3 指向不同的对象，lst3 指向另一对象，三者值(value)相等(==)。

结论：**可变数据类型赋值相同，引用不同。**

#### （2）不可变类型的赋值

```python
a = 9
b = a  
c = 9

print(a,id(a))
print(b,id(b))
print(c,id(c))
```

a、b、c 指向 **同一个对象**，小的整数和字符串被缓存并复用。

结论：**不可变类型赋值相同，引用相同。**

> 可变类型的内存是变化的，不可变类型的内存是不变的，对可变类型引用的变化会改变内存中的对象，对不可变类型引用的变化无法改变内存中的对象，只是改变了引用的指针。

### 4.浅拷贝

浅拷贝指的是对对象的拷贝，但是**浅拷贝只拷贝对象本身，并不会拷贝对象内部的嵌套对象。**因此对于内部的嵌套对象依然使用原始的引用。

#### （1）可变类型

```python
import copy

a = [1,2,3]
b = a
c = copy.copy(a)
a[0] = 3
print(a,b,c)  # [3, 2, 3];[3, 2, 3];[1,2,3]
print(id(a),id(b),id(c))  # 2521998388160 2521998388160 2521998392320
```

由于浅拷贝会对对象进行拷贝，因此对于可变类型而言，浅拷贝为对象开辟了新的内存空间，对原对象的改变不会再影响新对象，而赋值运算符仅仅是创建了原对象的新引用，因此改变原对象，引用也会改变。

#### （2）不可变类型

```python
import copy

a = 0
b = a
c = copy.copy(a)
a = 3
print(a,b,c)  # 3 0 0
print(id(a),id(b),id(c))  # 140712191779688 140712191779592 140712191779592
```

对于不可变类型而言，赋值改变了 变量`a`的引用，无法改变变量`b`引用的不可变对象，因此变量`b`引用的对象不会变化，由于不可变类型不会变化，因此没必要继续在内存中开辟新的不可变类型，继续拷贝对象引用即可。**不可变类型进行浅拷贝不会给拷贝的对象开辟新的内存空间，而只是拷贝了这个对象的引用。**

> 没有限制条件的分片表达式（`L[:]`）能够复制序列，但此法等价于浅拷贝。
>
> 增强赋值运算`a+=b`等和普通表达式`a=a+b`对于可变类型的操作有所区别，`a+=b`在`a`的内存上增加`b`，`a = a+b`则是在运算完`a`和`b`的内存相加后开辟新的内存并建立与`a`的引用，因此`a+=b`更高效。

### 5.深拷贝

深拷贝也是对对象的拷贝，**但是深拷贝不仅拷贝对象本身，还对对对象内部所有的嵌套对象进行递归拷贝**，深拷贝将被拷贝对象完全复制，因此深拷贝后的对象会作为新个体独立存在。

#### （1）可变类型的深拷贝

```python
import copy

a = [1,[2,3],[1,2,3]]
b = a
c = copy.copy(a)
d = copy.deepcopy(a)

a[0] = 8
a[2][0] = 9
print(a,b,c,d)
# [8, [2, 3], [9, 2, 3]] [8, [2, 3], [9, 2, 3]] [1, [2, 3], [9, 2, 3]] [1, [2, 3], [1, 2, 3]]
print(id(a),id(b),id(c),id(d))
# 2260189207040 2260189207040 2260189207104 2260189206912
```

这里可以看出，赋值符号仅仅拷贝了引用，因此对象id相同；浅拷贝仅仅对第一层列表进行了拷贝，因为二者`id`不同，但是当修改第一层列表时，被拷贝对象无变化，当修改第二层列表时，被拷贝对象发生了变化；深拷贝进行了完全拷贝，`id`值不同，且当对原列表修改多层时，新列表都没有发生变化。

#### （2）不可变类型的深拷贝

```python
import copy

a = (1, 2, [2,,3,4] )
b = a
c = copy.copy(a)
d = copy.deepcopy(a)

a[2][0] = 9
print(a,b,c,d)
# (1, 2, [9, 3, 4]) (1, 2, [9, 3, 4]) (1, 2, [9, 3, 4]) (1, 2, [2, 3, 4])
print(id(a),id(b),id(c),id(d))
# 2376658480000 2376658480000 2376658480000 2376658479936
```

同不可变类型的赋值与浅拷贝，对不可变类型的深拷贝仍然只是拷贝对象的引用，因此若一个不可变类型子对象中没有可变类型则不会对该对象进行拷贝，而只是拷贝了这个对象的引用。若一个不可变类型中存在可变类型，深拷贝对该对象到最后一个可变类型的每一层对象就行拷贝, 对每一层拷贝的对象都会开辟新的内存空间进行存储。

> 无论是赋值还是深拷贝或浅拷贝，对于完全不可变类型的操作都是拷贝其引用。区别仅仅在于，对于可变类型，赋值仅仅拷贝引用，浅拷贝仅仅开辟一层内存空间，深拷贝递归开辟所有内存空间。
>
> **注意：可变类型或包含可变类型的数据需要进行修改操作时，需要对其进行足够层次的拷贝，与深拷贝相比，浅拷贝当然更高效。**

## 三、垃圾回收

*`Python* `内部采用 **引用计数法** ，为每个对象维护引用次数，并据此回收不再需要的垃圾对象。由于引用计数法存在重大缺陷，循环引用时有内存泄露风险，因此 *`Python`* 还采用 **标记清除法** 来回收存在循环引用的垃圾对象。此外，为了提高垃圾回收( *GC* )效率，*Python* 还引入了 **分代回收机制** 。

### 1.引用计数(reference counting)

引用计数算法是最简单的垃圾回收算法即对象当没有引用指向时，会被回收(deallocated)。

在Python中每一个对象，甚至是int都有一个引用(pointer)指向该对象，为了保持对每个对象引用的跟踪，Python对象额外维护了一个`reference count`的变量来自增或自减，用来标识当前对象是在copy复制或者被delete删除。

对Python对象进行如下操作可以导致该对象的引用计数自增

- 赋值操作 `assignment operator`
- 函数传参 `argument passing`
- 将对象放到列表中 `appending an object to a list`

当对象的引用计数变量变为0时，`CPython`将会自动的调用该对象特定的回收方法`object-specific deallocation function`。

获取对象的引用计数可以通过`sys.getrefcount`方法

```python
foo = []
# 2 references, 1 from the foo var and 1 from getrefcount
print(sys.getrefcount(foo))
def bar(a):
    # 4 references
    # from the foo var, function argument, getrefcount and Python's function stack
    print(sys.getrefcount(a))
bar(foo)
# 2 references, the function scope is destroyed
print(sys.getrefcount(foo))
```

### 2.标记清除(Mark and Sweep)

标记清除算法主要有两段操作构成，即标记(Mark)，清除(Sweep)。

| 操作 | 说明                                                         |
| ---- | ------------------------------------------------------------ |
| 标记 | 从根节点出发检测所有不可达的节点对象，通常是DFS的遍历。      |
| 清除 | 清除标记中不可达的节点，通常就是遍历所有堆内存的对象并将未被标记的节点进行回收。 |

标记清除算法的优点在于可以解决循环引用的问题，并且在整个算法执行的过程中没有额外的开销。标记清除算法的最主要缺点在于正常的程序将会被阻塞，当执行标记清除时。另外一个缺点在于，标记清除算法在执行很多次数，在程序的堆空间会产生一些小的内存碎片。

### 3.分代回收(Generational garbage collector)

当出现经典的引用计数无法处理的循环引用问题时（循环引用或者自引用），分代回收的算法就登场了。 **分代回收算法是基于 标记清除(Mark and Sweep)**。首先GC分类器将对象分成3个不同代，每个新创建的对象属于第一代。每当对象在某代的的垃圾回收中存活下来时，则将该对象移动至下一代。较低的代会更加频繁的进行垃圾回收，(大部分对象在被创建后很快就会消亡)。分代垃圾回收提高了GC的性能，并降低了GC暂停时间。

与经典的引用计数不同的是，引用计数是实时工作的，而分代垃圾回收是定期工作的。为了决定在什么时候去执行分代垃圾回收，每一代都有各自独立的counter和threshold，counter为分配内存的对象数量减去上一次分代垃圾回收的数量。每次创建一个新的对象时，counter++，CPython就会检查counter是否达到了阈值，如果达到了阈值，则进行该代的垃圾回收。

> **简述python的垃圾回收机制**
> python的内存管理是通过引用计数+清理来完成的。因此python的垃圾回收机制，很大一部分主要是处理引用计数无法解决的循环引用。
> 1、标记清除算法：算法分为“标记”和“清除”两个阶段，首先标记所有需要回收的对象，在标记完成后统一回收所有被标记的对象。有两个不足：一是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发一次垃圾收集动作
> 2、复制算法：将内存分为两块，每次只使用其中的一块。当这一块内存用完了，就将还存活的对象复制到另一块上，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对一整块内存回收，内存分配时候也不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配即可，实现简单，运行高效。缺点是一次只能使用一部分内存，会有一些浪费。一般新生代会选择这种算法。
> 3、标记-整理算法：复制算法存在两个问题，1）会浪费50%的空间 2）如果被使用的内存中所有对象都100%存活的极端情况，就需要有额外的空间进行分配担保，因此老年代一般不能直接选用复制算法。有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”一样，后续步骤让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。
> 4、分代回收算法：分代回收算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。比如新生代和老年代，不同代使用不同的回收算法。比如新生代使用复制算法，而老年代使用标记-清除或标记-整理算法。

垃圾回收、循环引用和弱引用

Python使用了自动化内存管理，这种管理机制以**引用计数**为基础，同时也引入了**标记-清除**和**分代收集**两种机制为辅的策略。

```C
typedef struct _object {
    /* 引用计数 */
    int ob_refcnt;
    /* 对象指针 */
    struct _typeobject *ob_type;
} PyObject;
```

```C
/* 增加引用计数的宏定义 */
#define Py_INCREF(op)   ((op)->ob_refcnt++)
/* 减少引用计数的宏定义 */
#define Py_DECREF(op) \ //减少计数
    if (--(op)->ob_refcnt != 0) \
        ; \
    else \
        __Py_Dealloc((PyObject *)(op))
```

导致引用计数+1的情况：

- 对象被创建，例如`a = 23`
- 对象被引用，例如`b = a`
- 对象被作为参数，传入到一个函数中，例如`f(a)`
- 对象作为一个元素，存储在容器中，例如`list1 = [a, a]`

导致引用计数-1的情况：

- 对象的别名被显式销毁，例如`del a`
- 对象的别名被赋予新的对象，例如`a = 24`
- 一个对象离开它的作用域，例如f函数执行完毕时，f函数中的局部变量（全局变量不会）
- 对象所在的容器被销毁，或从容器中删除对象

引用计数可能会导致循环引用问题，而循环引用会导致内存泄露，如下面的代码所示。为了解决这个问题，Python中引入了“标记-清除”和“分代收集”。在创建一个对象的时候，对象被放在第一代中，如果在第一代的垃圾检查中对象存活了下来，该对象就会被放到第二代中，同理在第二代的垃圾检查中对象存活下来，该对象就会被放到第三代中。

```Python
# 循环引用会导致内存泄露 - Python除了引用技术还引入了标记清理和分代回收
# 在Python 3.6以前如果重写__del__魔术方法会导致循环引用处理失效
# 如果不想造成循环引用可以使用弱引用
list1 = []
list2 = [] 
list1.append(list2)
list2.append(list1)
```

以下情况会导致垃圾回收：

- 调用`gc.collect()`
- `gc`模块的计数器达到阀值
- 程序退出

如果循环引用中两个对象都定义了`__del__`方法，`gc`模块不会销毁这些不可达对象，因为gc模块不知道应该先调用哪个对象的`__del__`方法，这个问题在Python 3.6中得到了解决。

也可以通过`weakref`模块构造弱引用的方式来解决循环引用的问题。

## 四、数据与编码

### 1.编码回顾

`Python`代码头部理论上应该声明代码的编码，在`Python2`中编码类型默认为`ASCII`码，不支持中文，因此如果在代码中出现了中文或其他`ASCII`不支持的数据，将会引发异常。在`Python3`中默认编码为`utf8`，已经支持中文了，因此常常可以忽略声明代码，但是如果代码中出现了非`utf8`数据，也会引发报错，因此，建议养成在代码编写前提前声明编码的习惯。

```
# -*- encoding:utf-8 -*-
```

### 2.编码历史

|     名词     | 说明                                 |
| :----------: | ------------------------------------ |
|   字节Byte   | 计算机存储的最小单位,等于8位bit。    |
|     字符     | 单个的数字，文字，符号。             |
| 字符集(码表) | 存储字符与二进制序列的对应关系。     |
|     编码     | 将字符转换为对应的二进制序列的过程。 |
|     解码     | 将二进制序列转换为对应的字符的过程。 |

- `ASCII`（American Standard Code for Information Interchange，美国信息互换标准代码）是最早的编码，里面有英文大写字母，小写字母，数字及一些特殊字符（空格、标点等），这些大概一共使用了127个状态，随着计算机的不断发展，编码库中不断新增新的编码。由于八位的字节一共可以组合出256(2的8次方)种不同的状态，因此最终编码库处于饱和状态，无法继续增加新的符号。**一些标准中如SMTP协议中至今仍使用ASCII码，因此一些数据存放在邮件中跨国传输时仍会出现乱码现象。**

- `GB2312`当中国开始使用计算机时，已经没有可以利用的字节状态来表示汉字了，况且有6000多个常用汉字需要保存，因此中国将`ASCII`码中127位以后的特殊字符全部删除，并规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（称之为高字节）从0xA1用到0xF7，后面一个字节（低字节）从0xA1到0xFE，这样就可以组合出大约7000多个简体汉字了。在这些编码里还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的"全角"字符，而原来在127号以下的那些就叫"半角"字符。这种再`ASCII`前提下扩展汉字的方案叫做 `GB2312`，GB2312 是对 ASCII 的中文扩展。

- `GBK`中国汉字实在太多了，即使是`GB2312`也无法将全部的汉字都进行编码，因此再次对其进行改进。因此干脆不再要求低字节一定是127号之后的内码，只要第一个字节是大于127就固定表示这是一个汉字的开始，不管后面跟的是不是扩展字符集里的内容。结果扩展之后的编码方案被称为 `GBK `标准，GBK 包括了 GB2312 的所有内容，同时又增加了近20000个新的汉字（包括繁体字）和符号。随着时间的推移，`GBK`标准仍在不断扩充，诞生了`GB18030`等等。

> `GB18030`是`GBK`的超集，也就是包含的字符要比`GBK`多。不过像微软的`windows`和一些公司的`Linux`系统中的内嵌的中文编码都是`GBK`。其实`GB18030`比`GBK`中多出来的字符不是很常用，里面包含的主要是一些少数民族语言和一些韩语和维族语言。

- `ISO-8859-1`中国在计算机中扩展了汉字、其他国家也在`ASCII`码的基础上扩展了自己国家的语言，但是由于修改了基本的对应关系，导致各个国家之间的编码无法对应。这时出现了一个国际组织叫 `ISO` （国际标准化组织）决定着手解决这个问题，他们决定废了所有的地区性编码方案，重新搞一个包括了地球上所有文化、所有字母和符号的编码！他们打算叫它"`Universal Multiple-Octet Coded Character Set`"，简称 `UCS`, 俗称 "`UNICODE`"。当`UNICODE` 开始制订时，计算机的存储器容量极大地发展了，空间再也不成为问题了。于是` ISO` 就直接规定必须用两个字节，也就是16位来统一表示所有的字符，对于`ascii`里的那些“半角”字符，`UNICODE` 保持其原编码不变，只是将其长度由原来的8位扩展为16位，而其他文化和语言的字符则全部重新统一编码。由于"半角"英文符号只需要用到低8位，所以其高8位永远是0，因此这种大气的方案在保存英文文本时会多浪费一倍的空间。

  但是，`UNICODE` 在制订时没有考虑与任何一种现有的编码方案保持兼容，这使得 `GBK` 与`UNICODE` 在汉字的内码编排上完全是不一样的，没有一种简单的算术方法可以把文本内容从`UNICODE`编码和另一种编码进行转换，这种转换必须通过查表来进行。`UNICODE` 是用两个字节来表示为一个字符，总共可以组合出`65535`不同的字符，大概可以覆盖世界上所有文化的符号，`ISO`还准备了`UCS-4`方案，即四个字节来表示一个字符，这样就可以组合出21亿个不同的字符出来（最高位有其他用途）。

- `UNICODE` 来到时，一起到来的还有计算机网络的兴起，`UNICODE` 如何在网络上传输也是一个必须考虑的问题，于是面向传输的众多` UTF（UCS Transfer Format）`标准出现了，顾名思义，`UTF8`就是每次`8`个位传输数据，而`UTF16`就是每次16个位，只不过为了传输时的可靠性，从`UNICODE`到`UTF`时并不是直接的对应，而是要过一些算法和规则来转换。

> Windows一些底层中默认使用的仍然是`ASCII`码，因此一些中文名称可能会引起程序的报错，这是正常现象。
>
> 在数据传输时要注意数据的编码格式。

### 3.Python编码

Python3内存中，程序运行过程中的数据都是`unicode`编码，但在对数据进行存储或传输时，需要考虑将编码转化为`UTF-8`或者`GBK`，Python中提供了方法来讲文本信息进行编码。

|       函数       | 说明                     |
| :--------------: | ------------------------ |
| `encode(字符集)` | 将字符串编码为指定格式。 |
| `decode(字符集)` | 将指定编码解码为字符串。 |

> 编码的结果时`bytes`类型数据，英文如`b'alex'`与字符串一致，中文如`b'\xe4\xb8\xad'`，这是汉字的UTF-8的bytes表现形式。

了解更多[《字符集和字符编码》](https://www.cnblogs.com/skynet/archive/2011/05/03/2035105.html)。

